<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="1 K近邻分类器（KNN）KNN：通过计算待分类数据点与已有数据集中的所有数据点的距离，取距离最小的前K个点，根据“少数服从多数”的原则，将这个数据点划分为出现次数最多的那个类别。 1.1 sklearn中的K近邻分类器在sklearn库中，可以使用sklearn.neighbors.KNeighborsClassifier创建一个K近邻分类器，主要参数有：（1）n_neighbors：用于指定分">
<meta property="og:type" content="article">
<meta property="og:title" content="Python机器学习应用 | 基本分类模型">
<meta property="og:url" content="www.dongjinbao.com/机器学习/Python机器学习应用-基本分类模型.html">
<meta property="og:site_name" content="JinbaoSite">
<meta property="og:description" content="1 K近邻分类器（KNN）KNN：通过计算待分类数据点与已有数据集中的所有数据点的距离，取距离最小的前K个点，根据“少数服从多数”的原则，将这个数据点划分为出现次数最多的那个类别。 1.1 sklearn中的K近邻分类器在sklearn库中，可以使用sklearn.neighbors.KNeighborsClassifier创建一个K近邻分类器，主要参数有：（1）n_neighbors：用于指定分">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://oltfslql1.bkt.clouddn.com/knn.jpg">
<meta property="og:updated_time" content="2019-07-12T15:59:33.724Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python机器学习应用 | 基本分类模型">
<meta name="twitter:description" content="1 K近邻分类器（KNN）KNN：通过计算待分类数据点与已有数据集中的所有数据点的距离，取距离最小的前K个点，根据“少数服从多数”的原则，将这个数据点划分为出现次数最多的那个类别。 1.1 sklearn中的K近邻分类器在sklearn库中，可以使用sklearn.neighbors.KNeighborsClassifier创建一个K近邻分类器，主要参数有：（1）n_neighbors：用于指定分">
<meta name="twitter:image" content="http://oltfslql1.bkt.clouddn.com/knn.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="www.dongjinbao.com/机器学习/Python机器学习应用-基本分类模型.html">





  <title>Python机器学习应用 | 基本分类模型 | JinbaoSite</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JinbaoSite</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">每天努力一点点！</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-基本分类模型.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Python机器学习应用 | 基本分类模型</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-23T13:33:26+08:00">
                2017-06-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="1-K近邻分类器（KNN）"><a href="#1-K近邻分类器（KNN）" class="headerlink" title="1 K近邻分类器（KNN）"></a>1 K近邻分类器（KNN）</h2><p>KNN：通过计算待分类数据点与已有数据集中的所有数据点的距离，取距离最小的前K个点，根据“少数服从多数”的原则，将这个数据点划分为出现次数最多的那个类别。<br><img src="http://oltfslql1.bkt.clouddn.com/knn.jpg" alt></p>
<h3 id="1-1-sklearn中的K近邻分类器"><a href="#1-1-sklearn中的K近邻分类器" class="headerlink" title="1.1 sklearn中的K近邻分类器"></a>1.1 sklearn中的K近邻分类器</h3><p>在sklearn库中，可以使用sklearn.neighbors.KNeighborsClassifier创建一个K近邻分类器，主要参数有：<br>（1）n_neighbors：用于指定分类器中K的大小（默认值为5，注意与kmeans的区别）<br>（2）weights：设置选中的K个点对分类结果影响的权重（默认值为平均权重“uniform”，可以选择“distance”代码越近的点权重越高，或者传入自己编写的以距离为参数的权重计算函数）<br>（3）algorithm：设置用于计算临近点的方法，因为数据量很大的情况下计算当前点和所有点的距离再选出最近的k各点，这个计算量是很费时的，所以（选项中有ball_tree、kd_tree和brute，分别代表不同的寻找邻居的优化算法，默认值为auto，根据训练数据自动选择）</p>
<h3 id="1-2-K近邻分类器的使用"><a href="#1-2-K近邻分类器的使用" class="headerlink" title="1.2 K近邻分类器的使用"></a>1.2 K近邻分类器的使用</h3><p>创建一组数据X和它对应的标签y：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; X=[[0],[1],[2],[3]]</span><br><span class="line">&gt;&gt;&gt; y=[0,0,1,1]</span><br></pre></td></tr></table></figure>

<p>使用import语句导入K近邻分类器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier</span><br></pre></td></tr></table></figure>

<p>参数n_neighbors设置为3，即使用最近的3个邻居作为分类的依据，其他参数保持默认值，并将创建好的实例赋给变量neigh。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; neigh = KNeighborsClassifier(n_neighbors=3)</span><br></pre></td></tr></table></figure>

<p>调用fit()函数，将训练数据X和标签y送入分类器进行学习。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; neigh.fit(X,y)</span><br></pre></td></tr></table></figure>

<p>调用predict()函数，对未知分类样本[1.1]分类，可以直接并将需要分类的数据构造为数组形式作为参数传入，得到分类标签作为返回值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; print(neigh.predict([[1.1]]))</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p>样例输出值为0，表示K近邻分类器通过计算样本[1.1]与训练数据的距离取0,1,2这3个邻居作为依据，根据“投票法”最终将样本分为类别0。</p>
<h3 id="1-3-KNN的使用经验"><a href="#1-3-KNN的使用经验" class="headerlink" title="1.3 KNN的使用经验"></a>1.3 KNN的使用经验</h3><p>在实际使用时，我们可以使用所有训练结构构成特征X和标签y，使用fit()函数进行训练。在正式分类时，通过一次性构造测试集或者一个一个输入样本的方式，得到样本对应的分类结果。有关K的取值：<br>（1）如果K较大，相当于使用较大领域中的训练实例进行预测，可以减小估计误差，但是距离较远的样本也会对预测起作用，导致预测错误。<br>（2）如果K较小，相当于使用较小的领域进行预测，如果邻居恰好是噪声点，会导致过拟合。<br>（3）一般情况下，K会倾向选取较小的值，并使用交叉验证法选取最优K值。</p>
<h2 id="2-决策树"><a href="#2-决策树" class="headerlink" title="2 决策树"></a>2 决策树</h2><p>决策树是一种树形结构的分类器，通过顺序询问分类点的属性决定分类点最终的类别。通常根据特征的信息增益或其他指标，构建一颗决策树。在分类时，只需要按照决策树中的结点依次进行判断，即可得到样本所属类别。</p>
<h3 id="2-1-sklearn中的决策树"><a href="#2-1-sklearn中的决策树" class="headerlink" title="2.1 sklearn中的决策树"></a>2.1 sklearn中的决策树</h3><p>在sklearn库中，可以使用sklearn.tree.DecisionTreeClassifier创建一个决策树用于分类，其主要参数有：<br>（1）criterion：用于选择属性的准则，可以传入“个i你”代表基尼系数，或者“entropy”代表信息增益。<br>（2）max_features：表示在决策树结点进行分裂时，从多少个特征中选择最优特征。可以设定固定数目、百分比或其他标准。它的默认值是使用所有特征个数。</p>
<h3 id="2-2-决策树的使用"><a href="#2-2-决策树的使用" class="headerlink" title="2.2 决策树的使用"></a>2.2 决策树的使用</h3><p>首先，我们导入sklearn内嵌的鸢尾花数据集：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from sklearn.datasets import load_iris</span><br></pre></td></tr></table></figure>

<p>接下来，我们使用import语句导入决策树分类器，同时导入计算交叉验证值的函数cross_avl_score。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">&gt;&gt;&gt; from sklearn.model_selection import cross_val_score</span><br></pre></td></tr></table></figure>

<p>我们使用默认参数，创建一颗基于基尼系数的决策树，并将该决策树分类器赋值给变量clf。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; clf = DecisionTreeClassifier()</span><br></pre></td></tr></table></figure>

<p>将鸢尾花数据赋值给变量iris</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; iris = load_iris()</span><br></pre></td></tr></table></figure>

<p>这里我们将决策树分类器做为待评估的模型，iris.data鸢尾花数据做为特征，iris.target鸢尾花分类标签做为目标结果，通过设定cv为10，使用10折交叉验证。得到最终的交叉验证得分。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; cross_val_score(clf,iris.data,iris.target,cv=10)</span><br><span class="line">array([ 1.,  0.93333333,  1.,  0.93333333,  0.93333333,  0.86666667,  0.93333333,  0.93333333,  1.,  1.])</span><br></pre></td></tr></table></figure>

<p>以仿照之前K近邻分类器的使用方法，利用fit()函数训练模型并使用predict()函数预测：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; clf.fit(X,y)</span><br><span class="line">&gt;&gt;&gt; clf.predict(x)</span><br></pre></td></tr></table></figure>

<h3 id="2-3-决策树使用经验"><a href="#2-3-决策树使用经验" class="headerlink" title="2.3 决策树使用经验"></a>2.3 决策树使用经验</h3><p>决策树本质上是寻找一种对特征空间上的划分，旨在构建一个训练数据拟合的好，并且复杂度小的决策树。</p>
<p>在实际使用中，需要根据数据情况，调整DecisionTreeClassifier类中传入的参数，比如选择合适的criterion，设置随机变量等。</p>
<h2 id="3-朴素贝叶斯"><a href="#3-朴素贝叶斯" class="headerlink" title="3 朴素贝叶斯"></a>3 朴素贝叶斯</h2><p>朴素贝叶斯分类器是一个以贝叶斯定理为基础的多分类的分类器。<br>对于给定数据，首先基于特征的条件独立性假设，学习输入输出的联合概率分布，然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。<br>$$p(A|B) = \frac{p(B|A)*p(A)}{p(B)}$$</p>
<h3 id="3-1-sklearn中的朴素贝叶斯"><a href="#3-1-sklearn中的朴素贝叶斯" class="headerlink" title="3.1 sklearn中的朴素贝叶斯"></a>3.1 sklearn中的朴素贝叶斯</h3><p>在sklearn库中，实现了三个朴素贝叶斯分类器，如下：<br>| 分类器 | 描述 |<br>| :— | :— |<br>| naive_bayes.GussianNB | 高斯朴素贝叶斯 |<br>| naive_bayes.MultinamialNB | 针对多项式模型的朴素贝叶斯分类器 |<br>| naive_bayes.BernoulliNB | 针对多元伯努利模型的朴素贝叶斯分类器 |</p>
<p>区别在于假设某一特征的所有属于某个类别的观测值符合特定分布。</p>
<h3 id="3-2-sklearn中的朴素贝叶斯"><a href="#3-2-sklearn中的朴素贝叶斯" class="headerlink" title="3.2 sklearn中的朴素贝叶斯"></a>3.2 sklearn中的朴素贝叶斯</h3><p>在sklearn库中，可以使用sklearn.naive_bayes.GaussianNB创建一个高斯朴素贝叶斯分类器，其参数有：</p>
<ul>
<li>priors：给定各个类别的先验概率。如果为空，则按训练数据的实际情况进行统计；如果给定先验概率，则在训练过程中不能更改。</li>
</ul>
<h3 id="3-3-朴素贝叶斯的使用"><a href="#3-3-朴素贝叶斯的使用" class="headerlink" title="3.3 朴素贝叶斯的使用"></a>3.3 朴素贝叶斯的使用</h3><p>导入numpy库，并构造训练数据X和y</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import numpy as np</span><br><span class="line">&gt;&gt;&gt; X = np.array([[-1,-1],[-2,-1],[-3,-2],[1,1],[2,1],[3,2]])</span><br><span class="line">&gt;&gt;&gt; Y = np.array([1,1,1,2,2,2])</span><br></pre></td></tr></table></figure>

<p>使用import语句导入朴素贝叶斯分类器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from sklearn.naive_bayes import GaussianNB</span><br></pre></td></tr></table></figure>

<p>使用默认参数，创建一个高斯朴素贝叶斯分类器，并将该分类器赋值给clf。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; clf = GaussianNB(priors=None)</span><br></pre></td></tr></table></figure>

<p>类似的，使用fit()函数进行训练，并使用predict()函数进行预测，得到预测结果为1。（测试时可以构造二维数组达到同时预测多个样本的目的）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; clf.fit(X,Y)</span><br><span class="line">&gt;&gt;&gt; print(clf.predict([[-0.8,-1]]))</span><br><span class="line">[1]</span><br></pre></td></tr></table></figure>

<h3 id="3-3-朴素贝叶斯使用经验"><a href="#3-3-朴素贝叶斯使用经验" class="headerlink" title="3.3 朴素贝叶斯使用经验"></a>3.3 朴素贝叶斯使用经验</h3><p>朴素贝叶斯是典型的生成学习方法，由训练数据学习联合概率分布，并求得后验概率分布。</p>
<p>朴素贝叶斯一般在小规模数据上的表现非常好，适合进行多分类任务。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/机器学习/Python机器学习应用-监督学习.html" rel="next" title="Python机器学习应用 | 监督学习">
                <i class="fa fa-chevron-left"></i> Python机器学习应用 | 监督学习
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/机器学习/Python机器学习应用-人体运动状态预测.html" rel="prev" title="Python机器学习应用 | 人体运动状态预测">
                Python机器学习应用 | 人体运动状态预测 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">JinbaoSite</p>
              <p class="site-description motion-element" itemprop="description">趣头条广告算法工程师</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">58</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-K近邻分类器（KNN）"><span class="nav-number">1.</span> <span class="nav-text">1 K近邻分类器（KNN）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-sklearn中的K近邻分类器"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 sklearn中的K近邻分类器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-K近邻分类器的使用"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 K近邻分类器的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-KNN的使用经验"><span class="nav-number">1.3.</span> <span class="nav-text">1.3 KNN的使用经验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-决策树"><span class="nav-number">2.</span> <span class="nav-text">2 决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-sklearn中的决策树"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 sklearn中的决策树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-决策树的使用"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 决策树的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-决策树使用经验"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 决策树使用经验</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-朴素贝叶斯"><span class="nav-number">3.</span> <span class="nav-text">3 朴素贝叶斯</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-sklearn中的朴素贝叶斯"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 sklearn中的朴素贝叶斯</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-sklearn中的朴素贝叶斯"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 sklearn中的朴素贝叶斯</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-朴素贝叶斯的使用"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 朴素贝叶斯的使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-朴素贝叶斯使用经验"><span class="nav-number">3.4.</span> <span class="nav-text">3.3 朴素贝叶斯使用经验</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JinbaoSite</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
