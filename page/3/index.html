<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="趣头条广告算法工程师">
<meta property="og:type" content="website">
<meta property="og:title" content="JinbaoSite">
<meta property="og:url" content="www.dongjinbao.com/page/3/index.html">
<meta property="og:site_name" content="JinbaoSite">
<meta property="og:description" content="趣头条广告算法工程师">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="JinbaoSite">
<meta name="twitter:description" content="趣头条广告算法工程师">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="www.dongjinbao.com/page/3/">





  <title>JinbaoSite</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">JinbaoSite</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">每天努力一点点！</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-岭回归.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-岭回归.html" itemprop="url">Python机器学习应用 | 岭回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-30T10:53:28+08:00">
                2017-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-岭回归"><a href="#1-岭回归" class="headerlink" title="1 岭回归"></a>1 岭回归</h2><p>对于一般地线性回归问题，参数的求解采用的是最小二乘法，其目标函数如下：<br>$$argmin || Xw-y ||^2$$<br>参数w的求解，也可以使用如下矩阵方法进行：<br>$$w=(X^TX)^{-1}X^Ty$$<br>对于矩阵X，若某些列线性相关性较大（即训练样本中某些属性线性相关），就会导致$X^TX$的值接近0，在计算 $(X^TX)^{-1}$时就会出现不稳定性：<br>结论：传统的基于最小二乘的线性回归法缺乏稳定性。</p>
<p>岭回归的优化目标:<br>$$argmin || Xw-y ||^2 + \alpha ||w||^2$$<br>对应的矩阵求解方法为:<br>$$w=(X^TX+ \alpha I)^{-1}X^Ty$$</p>
<p>岭回归(ridge regression)是一种专用于共线性数据分析的有偏估计回归方法,是一种改良的最小二乘估计法，对某些数据的拟合要强于最小二乘法。</p>
<h2 id="2-sklearn中的岭回归"><a href="#2-sklearn中的岭回归" class="headerlink" title="2 sklearn中的岭回归"></a>2 sklearn中的岭回归</h2><p>在sklearn库中，可以使用sklearn.linear_model.Ridge调用岭回归模型，其主要参数有：<br>• alpha：正则化因子，对应于损失函数中的</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-降维——NMF方法及实例.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-降维——NMF方法及实例.html" itemprop="url">Python机器学习应用 | 降维——NMF方法及实例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-29T22:24:34+08:00">
                2017-06-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-非负矩阵分解（NMF）"><a href="#1-非负矩阵分解（NMF）" class="headerlink" title="1 非负矩阵分解（NMF）"></a>1 非负矩阵分解（NMF）</h2><p>1、非负矩阵分解（Non-negative Matrix Factorization ，NMF）是在矩阵中所有元素均为非负数约束条件之下的矩阵分解方法。<br>2、基本思想：给定一个非负矩阵V，NMF能够找到一个非负矩阵W和一个非负矩阵H，使得矩阵W和H的乘积近似等于矩阵V中的值。<br>$$V_{n<em>m}=W_{n</em>k}<em>H_{k</em>m}$$<br><img src="http://oltfslql1.bkt.clouddn.com/whv.jpg" alt><br>W矩阵：基础图像矩阵，相当于从原矩阵V中抽取出来的特征<br>H矩阵：系数矩阵。<br>3、NMF能够广泛应用于图像分析、文本挖掘和语音处理等领域。<br>4、矩阵分解优化目标：最小化W矩阵H矩阵的乘积和原始矩阵之间的差别，目标函数如下：<br>$$argmin \frac{1}{2} ||X-WH||^2 = \frac{1}{2} \sum_{i,j}(x_{ij}-WH_{ij})^2$$<br>5、基于KL散度的优化目标，损失函数如下：<br>$$argmin J(W,H)=\sum_{ij}(X_{ij}ln \frac{ X_{ij} }{ WH_{ij} } - X_{ij} + WH_{ij})$$</p>
<h2 id="2-sklearn中非负矩阵分解"><a href="#2-sklearn中非负矩阵分解" class="headerlink" title="2 sklearn中非负矩阵分解"></a>2 sklearn中非负矩阵分解</h2><p>在sklearn库中，可以使用sklearn.decomposition.NMF加NMF算法，主要参数有：<br>• n_components：用于指定分解后矩阵的单个维度k；<br>• init：W矩阵和H矩阵的初始化方式，默认为‘nndsvdar’。</p>
<h2 id="3-NMF人脸数据特征提取"><a href="#3-NMF人脸数据特征提取" class="headerlink" title="3 NMF人脸数据特征提取"></a>3 NMF人脸数据特征提取</h2><h3 id="3-1-背景"><a href="#3-1-背景" class="headerlink" title="3.1 背景"></a>3.1 背景</h3><p>已知Olivetti人脸数据共400个，每个数据是64*64大小。由于NMF分解得到的W矩阵相当于从原始矩阵中提取的特征，那么就可以使用NMF对400个人脸数据进行特征提取。<br>通过设置k的大小，设置提取的特征的数目。在本实验中设置k=6，随后将提取的特征以图像的形式展示出来。</p>
<h3 id="3-2-程序编写"><a href="#3-2-程序编写" class="headerlink" title="3.2 程序编写"></a>3.2 程序编写</h3><h4 id="3-2-1-建立工程，导入sklearn相关工具包"><a href="#3-2-1-建立工程，导入sklearn相关工具包" class="headerlink" title="3.2.1 建立工程，导入sklearn相关工具包"></a>3.2.1 建立工程，导入sklearn相关工具包</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import matplotlib.pyplot as plt</span><br><span class="line">#加载matplotlib用于数据的可视化</span><br><span class="line">&gt;&gt;&gt; from sklearn import decomposition</span><br><span class="line">#加载PCA算法包</span><br><span class="line">&gt;&gt;&gt; from sklearn.datasets import fetch_olivetti_faces</span><br><span class="line">#加载Olivetti人脸数据集导入函数</span><br><span class="line">&gt;&gt;&gt; from numpy.random import RandomState</span><br><span class="line">#加载RandomState用于创建随机种子</span><br></pre></td></tr></table></figure>

<h4 id="3-2-2-设置基本参数并加载数据"><a href="#3-2-2-设置基本参数并加载数据" class="headerlink" title="3.2.2 设置基本参数并加载数据"></a>3.2.2 设置基本参数并加载数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">n_row, n_col = 2, 3 #设置图像展示时的排列情况</span><br><span class="line">n_components = n_row * n_col #设置提取的特征的数目</span><br><span class="line">image_shape = (64, 64) #设置人脸数据图片的大小</span><br><span class="line">dataset = fetch_olivetti_faces(shuffle=True,random_state=RandomState(0))</span><br><span class="line">faces = datasets.data #加载数据，并打乱顺序</span><br></pre></td></tr></table></figure>

<h4 id="3-2-3-设置图像的展示方式"><a href="#3-2-3-设置图像的展示方式" class="headerlink" title="3.2.3 设置图像的展示方式"></a>3.2.3 设置图像的展示方式</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def plot_gallery(title, images, n_col=n_col, n_row=n_row):</span><br><span class="line">    plt.figure(figsize=(2. * n_col, 2.26 * n_row)) </span><br><span class="line">    plt.suptitle(title, size=16)</span><br><span class="line"> </span><br><span class="line">    for i, comp in enumerate(images):</span><br><span class="line">        plt.subplot(n_row, n_col, i + 1)</span><br><span class="line">        vmax = max(comp.max(), -comp.min())</span><br><span class="line"> </span><br><span class="line">        plt.imshow(comp.reshape(image_shape), cmap=plt.cm.gray,</span><br><span class="line">                   interpolation=&apos;nearest&apos;, vmin=-vmax, vmax=vmax)</span><br><span class="line">        plt.xticks(())</span><br><span class="line">        plt.yticks(())</span><br><span class="line">    plt.subplots_adjust(0.01, 0.05, 0.99, 0.94, 0.04, 0.)</span><br></pre></td></tr></table></figure>

<h4 id="3-2-4-创建特征提取的对象NMF，使用PCA作为对比"><a href="#3-2-4-创建特征提取的对象NMF，使用PCA作为对比" class="headerlink" title="3.2.4 创建特征提取的对象NMF，使用PCA作为对比"></a>3.2.4 创建特征提取的对象NMF，使用PCA作为对比</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">estimators = [</span><br><span class="line">    (&apos;Eigenfaces - PCA using randomized SVD&apos;,</span><br><span class="line">         decomposition.PCA(n_components=6,whiten=True)),</span><br><span class="line"> </span><br><span class="line">    (&apos;Non-negative components - NMF&apos;,</span><br><span class="line">         decomposition.NMF(n_components=6, init=&apos;nndsvda&apos;, tol=5e-3))</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h4 id="3-2-5-降维后数据点的可视化"><a href="#3-2-5-降维后数据点的可视化" class="headerlink" title="3.2.5 降维后数据点的可视化"></a>3.2.5 降维后数据点的可视化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for name, estimator in estimators:</span><br><span class="line">    print(&quot;Extracting the top %d %s...&quot; % (n_components, name))</span><br><span class="line">    print(faces.shape)</span><br><span class="line">    estimator.fit(faces)</span><br><span class="line">    components_ = estimator.components_</span><br><span class="line">    plot_gallery(name, components_[:n_components])</span><br><span class="line"> </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="3-3-结果展示"><a href="#3-3-结果展示" class="headerlink" title="3.3 结果展示"></a>3.3 结果展示</h3><p><img src="http://oltfslql1.bkt.clouddn.com/svdans.jpg" alt><img src="http://oltfslql1.bkt.clouddn.com/nmfans.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-降维——PCA方法及其应用.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-降维——PCA方法及其应用.html" itemprop="url">Python机器学习应用 | 降维——PCA方法及其应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-29T19:10:53+08:00">
                2017-06-29
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-主成分分析（PCA）"><a href="#1-主成分分析（PCA）" class="headerlink" title="1 主成分分析（PCA）"></a>1 主成分分析（PCA）</h2><p>1、主成分分析（Principal Component Analysis，PCA）是最常用的一种降维方法，通常用于高维数据集的探索与可视化，还可以用作数据压缩和预处理等。<br>2、PCA可以把具有相关性的高维变量合成为线性无关的低维变量，称为主成分。主成分能够尽可能保留原始数据的信息。<br>3、矩阵的主成分就是其协方差矩阵对应的特征向量，按照对应的特征值大小进行排序，最大的特征值就是第一主成分，其次是第二主成分，以此类推。</p>
<h2 id="2-算法过程"><a href="#2-算法过程" class="headerlink" title="2 算法过程"></a>2 算法过程</h2><p>输入：样本集$D=${$x_1,x_2,…,x_m$};低维空间维数$d’$<br>过程：<br>1、对所有样本进行中心化：$x_1 \leftarrow x_i - \frac{1}{m} \sum_{i=1}^{m} x_i$;<br>2、计算样本的协方差矩阵$XX^T$;<br>3、对协方差矩阵$XX^T$做特征值分解;<br>4、取最大的$d’$个特征值所对应的特征值$w_1,w_2,…,w_{d’}$;<br>输出：投影矩阵$W = (w_1,w_2,…,w_{d’})$。</p>
<h2 id="3-sklearn中主成分分析"><a href="#3-sklearn中主成分分析" class="headerlink" title="3 sklearn中主成分分析"></a>3 sklearn中主成分分析</h2><p>在sklearn库中，可以使用sklearn.decomposition.PCA加载PCA进行降维，主要参数有：<br>• n_components：指定主成分的个数，即降维后数据的维度<br>• svd_solver ：设置特征值分解的方法，默认为‘auto’,其他可选有‘full’, ‘arpack’, ‘randomized’。</p>
<h2 id="4-PCA实现高维数据可视化"><a href="#4-PCA实现高维数据可视化" class="headerlink" title="4 PCA实现高维数据可视化"></a>4 PCA实现高维数据可视化</h2><h3 id="4-1-背景"><a href="#4-1-背景" class="headerlink" title="4.1 背景"></a>4.1 背景</h3><p>目标：已知鸢尾花数据是4维的，共三类样本。使用PCA实现对鸢尾花数据进行降维，实现在二维平面上的可视化。<br><img src="http://oltfslql1.bkt.clouddn.com/yah.jpg" alt></p>
<h3 id="4-2-程序编写"><a href="#4-2-程序编写" class="headerlink" title="4.2 程序编写"></a>4.2 程序编写</h3><h4 id="4-2-1-建立工程，导入sklearn相关工具包："><a href="#4-2-1-建立工程，导入sklearn相关工具包：" class="headerlink" title="4.2.1 建立工程，导入sklearn相关工具包："></a>4.2.1 建立工程，导入sklearn相关工具包：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import matplotlib.pyplot as plt</span><br><span class="line">#加载matplotlib用于数据的可视化</span><br><span class="line">&gt;&gt;&gt; from sklearn.decomposition import PCA</span><br><span class="line">#加载PCA算法包</span><br><span class="line">&gt;&gt;&gt; from sklearn.datasets import load_iris</span><br><span class="line">#加载鸢尾花数据集导入函数</span><br></pre></td></tr></table></figure>

<h4 id="4-2-2-加载数据并进行降维"><a href="#4-2-2-加载数据并进行降维" class="headerlink" title="4.2.2 加载数据并进行降维"></a>4.2.2 加载数据并进行降维</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; data = load_iris()</span><br><span class="line">#以字典形式加载鸢尾花数据集</span><br><span class="line">&gt;&gt;&gt; y = data.target #使用y表示数据集中的标签</span><br><span class="line">&gt;&gt;&gt; X = data.data #使用X表示数据集中的属性数据</span><br><span class="line">&gt;&gt;&gt; pca = PCA(n_components=2)</span><br><span class="line">#加载PCA算法，设置降维后主成分数目为2</span><br><span class="line">&gt;&gt;&gt; reduced_X = pca.fit_transform(X)</span><br><span class="line">#对原始数据进行降维，保存在reduced_X中</span><br></pre></td></tr></table></figure>

<h4 id="4-2-3-按类别对降维后的数据进行保存"><a href="#4-2-3-按类别对降维后的数据进行保存" class="headerlink" title="4.2.3 按类别对降维后的数据进行保存"></a>4.2.3 按类别对降维后的数据进行保存</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; red_x, red_y = [], []</span><br><span class="line">#第一类数据点</span><br><span class="line">&gt;&gt;&gt; blue_x, blue_y = [], []</span><br><span class="line">#第二类数据点</span><br><span class="line">&gt;&gt;&gt; green_x, green_y = [], []</span><br><span class="line">#第三类数据点</span><br><span class="line">&gt;&gt;&gt; for i in range(len(reduced_X)):</span><br><span class="line">&gt;&gt;&gt;     if y[i] == 0:</span><br><span class="line">&gt;&gt;&gt;         red_x.append(reduced_X[i][0])</span><br><span class="line">&gt;&gt;&gt;         red_y.append(reduced_X[i][1])</span><br><span class="line">&gt;&gt;&gt;     elif y[i] == 1:</span><br><span class="line">&gt;&gt;&gt;         blue_x.append(reduced_X[i][0])</span><br><span class="line">&gt;&gt;&gt;         blue_y.append(reduced_X[i][1])</span><br><span class="line">&gt;&gt;&gt;     else:</span><br><span class="line">&gt;&gt;&gt;         green_x.append(reduced_X[i][0])</span><br><span class="line">&gt;&gt;&gt;         green_y.append(reduced_X[i][1])</span><br></pre></td></tr></table></figure>

<h4 id="4-2-4-降维后数据点的可视化"><a href="#4-2-4-降维后数据点的可视化" class="headerlink" title="4.2.4 降维后数据点的可视化"></a>4.2.4 降维后数据点的可视化</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; plt.scatter(red_x, red_y, c=&apos;r&apos;, marker=&apos;x&apos;)</span><br><span class="line">#第一类数据点</span><br><span class="line">&gt;&gt;&gt; plt.scatter(blue_x, blue_y, c=&apos;b&apos;, marker=&apos;D&apos;)</span><br><span class="line">#第二类数据点</span><br><span class="line">&gt;&gt;&gt; plt.scatter(green_x, green_y, c=&apos;g&apos;, marker=&apos;.&apos;)</span><br><span class="line">#第三类数据点</span><br><span class="line">&gt;&gt;&gt; plt.show()</span><br><span class="line">#可视化</span><br></pre></td></tr></table></figure>

<h3 id="4-3-结果展示"><a href="#4-3-结果展示" class="headerlink" title="4.3 结果展示"></a>4.3 结果展示</h3><p><img src="http://oltfslql1.bkt.clouddn.com/yanhua.jpg" alt><br>可以看出，降维后的数据仍能够清晰地分成三类。这样不仅能削减数据的维度，降低分类任务的工作量，还能保证分类的质量。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-聚类——DBSCAN方法及应用.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-聚类——DBSCAN方法及应用.html" itemprop="url">Python机器学习应用 | 聚类——DBSCAN方法及应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-27T15:03:00+08:00">
                2017-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-DBSCAN密度聚类"><a href="#1-DBSCAN密度聚类" class="headerlink" title="1 DBSCAN密度聚类"></a>1 DBSCAN密度聚类</h2><p>DBSCAN算法是一种基于密度的聚类算法：<br>• 聚类的时候不需要预先指定簇的个数<br>• 最终的簇的个数不定</p>
<p>DBSCAN算法将数据点分为三类：<br>• 核心点：在半径Eps内含有超过MinPts数目的点<br>• 边界点：在半径Eps内点的数量小于MinPts，但是落在核心点的邻域内<br>• 噪音点：既不是核心点也不是边界点的点</p>
<p><img src="http://oltfslql1.bkt.clouddn.com/dbscan.jpg" alt></p>
<h2 id="2-DBSCAN算法流程"><a href="#2-DBSCAN算法流程" class="headerlink" title="2 DBSCAN算法流程"></a>2 DBSCAN算法流程</h2><p>1.将所有点标记为核心点、边界点或噪声点；<br>2.删除噪声点；<br>3.为距离在Eps之内的所有核心点之间赋予一条边；<br>4.每组连通的核心点形成一个簇；<br>5.将每个边界点指派到一个与之关联的核心点的簇中（哪一个核心点的半径范围之内）。</p>
<p>有如下13个样本点，使用DBSCAN进行聚类<br><img src="http://oltfslql1.bkt.clouddn.com/db.jpg" alt><br>取Eps=3，MinPts=3，依据DBSACN对所有点进行聚类（曼哈顿距离）。<br><img src="http://oltfslql1.bkt.clouddn.com/eps.jpg" alt><br>对每个点计算其邻域Eps=3内的点的集合。<br>集合内点的个数超过MinPts=3的点为核心点<br>查看剩余点是否在核心点的邻域内，若在，则为边界点，否则为噪声点。<br><img src="http://oltfslql1.bkt.clouddn.com/min.jpg" alt><br>将距离不超过Eps=3的点相互连接，构成一个簇，核心点邻域内的点也会被加入到这个簇中。则右侧形成3个簇。<br><img src="http://oltfslql1.bkt.clouddn.com/mini.jpg" alt></p>
<h2 id="3-DBSCAN的应用实例"><a href="#3-DBSCAN的应用实例" class="headerlink" title="3 DBSCAN的应用实例"></a>3 DBSCAN的应用实例</h2><h3 id="3-1-数据介绍"><a href="#3-1-数据介绍" class="headerlink" title="3.1 数据介绍"></a>3.1 数据介绍</h3><p>现有大学校园网的日志数据，290条大学生的校园网使用情况数据，数据包括用户ID，设备的MAC地址，IP地址，开始上网时间，停止上网时间，上网时长，校园网套餐等。利用已有数据，分析学生上网的模式。</p>
<h3 id="3-2-实验目的"><a href="#3-2-实验目的" class="headerlink" title="3.2 实验目的"></a>3.2 实验目的</h3><p>通过DBSCAN聚类，分析学生上网时间和上网时长的模式。<br>技术路线：sklearn.cluster.DBSCAN</p>
<h3 id="3-3-数据实例"><a href="#3-3-数据实例" class="headerlink" title="3.3 数据实例"></a>3.3 数据实例</h3><p><img src="http://oltfslql1.bkt.clouddn.com/stu.jpg" alt></p>
<h3 id="3-4-实验过程"><a href="#3-4-实验过程" class="headerlink" title="3.4 实验过程"></a>3.4 实验过程</h3><p>使用算法： DBSCAN聚类算法<br><img src="http://oltfslql1.bkt.clouddn.com/gong.jpg" alt></p>
<h4 id="3-4-1-建立工程，导入sklearn相关包"><a href="#3-4-1-建立工程，导入sklearn相关包" class="headerlink" title="3.4.1 建立工程，导入sklearn相关包"></a>3.4.1 建立工程，导入sklearn相关包</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import sklearn.cluster as skc</span><br><span class="line">from sklearn import metrics</span><br><span class="line">import matplotlib.pyplot as plt</span><br></pre></td></tr></table></figure>

<h4 id="3-4-2-读入数据并进行处理"><a href="#3-4-2-读入数据并进行处理" class="headerlink" title="3.4.2 读入数据并进行处理"></a>3.4.2 读入数据并进行处理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mac2id=dict()</span><br><span class="line">onlinetimes=[]</span><br><span class="line">f=open(&apos;TestData.txt&apos;,encoding=&apos;utf-8&apos;)</span><br><span class="line">for line in f:</span><br><span class="line">    mac=line.split(&apos;,&apos;)[2]</span><br><span class="line">    onlinetime=int(line.split(&apos;,&apos;)[6])</span><br><span class="line">    starttime=int(line.split(&apos;,&apos;)[4].split(&apos; &apos;)[1].split(&apos;:&apos;)[0])</span><br><span class="line">    if mac not in mac2id:</span><br><span class="line">        mac2id[mac]=len(onlinetimes)</span><br><span class="line">        onlinetimes.append((starttime,onlinetime))</span><br><span class="line">    else:</span><br><span class="line">        onlinetimes[mac2id[mac]]=[(starttime,onlinetime)]</span><br><span class="line">real_X=np.array(onlinetimes).reshape((-1,2))</span><br></pre></td></tr></table></figure>

<h4 id="3-4-3-上网时间聚类，创建DBSCAN算法实例，并进行训练，获得标签"><a href="#3-4-3-上网时间聚类，创建DBSCAN算法实例，并进行训练，获得标签" class="headerlink" title="3.4.3 上网时间聚类，创建DBSCAN算法实例，并进行训练，获得标签"></a>3.4.3 上网时间聚类，创建DBSCAN算法实例，并进行训练，获得标签</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X=real_X[:,0:1]</span><br><span class="line"> </span><br><span class="line">db=skc.DBSCAN(eps=0.01,min_samples=20).fit(X)</span><br><span class="line">labels = db.labels_</span><br></pre></td></tr></table></figure>

<h4 id="3-4-4-输出标签，查看结果"><a href="#3-4-4-输出标签，查看结果" class="headerlink" title="3.4.4 输出标签，查看结果"></a>3.4.4 输出标签，查看结果</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">print(&apos;Labels:&apos;)</span><br><span class="line">print(labels)</span><br><span class="line">raito=len(labels[labels[:] == -1]) / len(labels)</span><br><span class="line">print(&apos;Noise raito:&apos;,format(raito, &apos;.2%&apos;))</span><br><span class="line"> </span><br><span class="line">n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)</span><br><span class="line"> </span><br><span class="line">print(&apos;Estimated number of clusters: %d&apos; % n_clusters_)</span><br><span class="line">print(&quot;Silhouette Coefficient: %0.3f&quot;% metrics.silhouette_score(X, labels))</span><br><span class="line"> </span><br><span class="line">for i in range(n_clusters_):</span><br><span class="line">    print(&apos;Cluster &apos;,i,&apos;:&apos;)</span><br><span class="line">    print(list(X[labels == i].flatten()))</span><br></pre></td></tr></table></figure>

<p>结果如下：<br><img src="http://oltfslql1.bkt.clouddn.com/ans.jpg" alt></p>
<h4 id="3-4-5-画直方图，分析实验结果"><a href="#3-4-5-画直方图，分析实验结果" class="headerlink" title="3.4.5 画直方图，分析实验结果"></a>3.4.5 画直方图，分析实验结果</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.hist(X,24)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="http://oltfslql1.bkt.clouddn.com/figure_1.jpeg" alt><br>上网时间大多聚集在22：00和23：00</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-聚类——K-means方法及应用.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-聚类——K-means方法及应用.html" itemprop="url">Python机器学习应用 | 聚类——K-means方法及应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-27T14:41:06+08:00">
                2017-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-K-means聚类算法"><a href="#1-K-means聚类算法" class="headerlink" title="1 K-means聚类算法"></a>1 K-means聚类算法</h2><p>k-means算法以k为参数，把n个对象分成k个簇，使簇内具有较高的相似度，而簇间的相似度较低。其处理过程如下：<br>1.随机选择k个点作为初始的聚类中心；<br>2.对于剩下的点，根据其与聚类中心的距离，将其归入最近的簇<br>3.对每个簇，计算所有点的均值作为新的聚类中心<br>4.重复2、3直到聚类中心不再发生改变<br><img src="http://oltfslql1.bkt.clouddn.com/julei.jpg" alt></p>
<h2 id="2-K-means的应用"><a href="#2-K-means的应用" class="headerlink" title="2 K-means的应用"></a>2 K-means的应用</h2><h3 id="2-1-数据介绍"><a href="#2-1-数据介绍" class="headerlink" title="2.1 数据介绍"></a>2.1 数据介绍</h3><p>现有1999年全国31个省份城镇居民家庭平均每人全年消费性支出的八个主要变量数据，这八个变量分别是：食品、衣着、家庭设备用品及服务、医疗保健、交通和通讯、娱乐教育文化服务、居住以及杂项商品和服务。利用已有数据，对31个省份进行聚类。</p>
<h3 id="2-2-实验目的"><a href="#2-2-实验目的" class="headerlink" title="2.2 实验目的"></a>2.2 实验目的</h3><p>通过聚类，了解1999年各个省份的消费水平在国内的情况。<br>技术路线：sklearn.cluster.Kmeans</p>
<h3 id="2-3-数据实例"><a href="#2-3-数据实例" class="headerlink" title="2.3 数据实例"></a>2.3 数据实例</h3><p><img src="http://oltfslql1.bkt.clouddn.com/datatable.jpg" alt></p>
<h3 id="2-4-实验过程"><a href="#2-4-实验过程" class="headerlink" title="2.4 实验过程"></a>2.4 实验过程</h3><p>使用算法： K-means聚类算法</p>
<h4 id="2-4-1-建立工程，导入sklearn相关包"><a href="#2-4-1-建立工程，导入sklearn相关包" class="headerlink" title="2.4.1 建立工程，导入sklearn相关包"></a>2.4.1 建立工程，导入sklearn相关包</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from sklearn.cluster import KMeans</span><br></pre></td></tr></table></figure>

<h4 id="2-4-2-加载数据，创建K-means算法实例，并进行训练，获得标签"><a href="#2-4-2-加载数据，创建K-means算法实例，并进行训练，获得标签" class="headerlink" title="2.4.2 加载数据，创建K-means算法实例，并进行训练，获得标签"></a>2.4.2 加载数据，创建K-means算法实例，并进行训练，获得标签</h4><p>1.利用loadData方法读取数据<br>2.创建实例<br>3.调用Kmeans()、fit_predict()方法进行计算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def loadData(filePath):</span><br><span class="line">    fr = open(filePath,&apos;r+&apos;)</span><br><span class="line">    lines = fr.readlines()</span><br><span class="line">    retData = []</span><br><span class="line">    retCityName = []</span><br><span class="line">    for line in lines:</span><br><span class="line">        items = line.strip().split(&quot;,&quot;)</span><br><span class="line">        retCityName.append(items[0])</span><br><span class="line">        retData.append([float(items[i]) for i in range(1,len(items))])</span><br><span class="line">    return retData,retCityName</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    data,cityName = loadData(&apos;city.txt&apos;)</span><br><span class="line">    km = KMeans(n_clusters=4)</span><br><span class="line">    label = km.fit_predict(data)</span><br><span class="line">    expenses = np.sum(km.cluster_centers_,axis=1)</span><br><span class="line">    #print(expenses)</span><br><span class="line">    CityCluster = [[],[],[],[]]</span><br><span class="line">    for i in range(len(cityName)):</span><br><span class="line">        CityCluster[label[i]].append(cityName[i])</span><br><span class="line">    for i in range(len(CityCluster)):</span><br><span class="line">        print(&quot;Expenses:%.2f&quot; % expenses[i])</span><br><span class="line">        print(CityCluster[i])</span><br></pre></td></tr></table></figure>

<p>调用KMeans方法所需参数：<br>• n_clusters：用于指定聚类中心的个数<br>• init：初始聚类中心的初始化方法<br>• max_iter：最大的迭代次数<br>• 一般调用时只用给出n_clusters即可，init默认是k-means++，max_iter默认是300</p>
<p>其它参数：<br>• data：加载的数据<br>• label：聚类后各数据所属的标签<br>• axis: 按行求和<br>• fit_predict()：计算簇中心以及为簇分配序号</p>
<h4 id="2-4-3-输出标签，查看结果"><a href="#2-4-3-输出标签，查看结果" class="headerlink" title="2.4.3 输出标签，查看结果"></a>2.4.3 输出标签，查看结果</h4><ul>
<li>将城市按照消费水平n_clusters类，消费水平相近的城市聚集在一类中</li>
<li>expense：聚类中心点的数值加和，也就是平均消费水平</li>
</ul>
<p>聚成2类：km = KMeans(n_clusters=2)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Expenses:4040.42</span><br><span class="line">[&apos;河北&apos;, &apos;山西&apos;, &apos;内蒙古&apos;, &apos;辽宁&apos;, &apos;吉林&apos;, &apos;黑龙江&apos;, &apos;江苏&apos;, &apos;安徽&apos;, &apos;江西&apos;, &apos;山东&apos;, &apos;河南&apos;, &apos;湖南&apos;, &apos;湖北&apos;, &apos;广西&apos;, &apos;海南&apos;, &apos;四川&apos;, &apos;贵州&apos;, &apos;云南&apos;, &apos;陕西&apos;, &apos;甘肃&apos;, &apos;青海&apos;, &apos;宁夏&apos;, &apos;新疆&apos;]</span><br><span class="line">Expenses:6457.13</span><br><span class="line">[&apos;北京&apos;, &apos;天津&apos;, &apos;上海&apos;, &apos;浙江&apos;, &apos;福建&apos;, &apos;广东&apos;, &apos;重庆&apos;, &apos;西藏&apos;]</span><br></pre></td></tr></table></figure>

<p>聚成3类：km = KMeans(n_clusters=3)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Expenses:3827.87</span><br><span class="line">[&apos;河北&apos;, &apos;山西&apos;, &apos;内蒙古&apos;, &apos;辽宁&apos;, &apos;吉林&apos;, &apos;黑龙江&apos;, &apos;安徽&apos;, &apos;江西&apos;, &apos;山东&apos;, &apos;河南&apos;, &apos;湖北&apos;, &apos;贵州&apos;, &apos;陕西&apos;, &apos;甘肃&apos;, &apos;青海&apos;, &apos;宁夏&apos;, &apos;新疆&apos;]</span><br><span class="line">Expenses:5113.54</span><br><span class="line">[&apos;天津&apos;, &apos;江苏&apos;, &apos;浙江&apos;, &apos;福建&apos;, &apos;湖南&apos;, &apos;广西&apos;, &apos;海南&apos;, &apos;重庆&apos;, &apos;四川&apos;, &apos;云南&apos;, &apos;西藏&apos;]</span><br><span class="line">Expenses:7754.66</span><br><span class="line">[&apos;北京&apos;, &apos;上海&apos;, &apos;广东&apos;]</span><br></pre></td></tr></table></figure>

<p>聚成4类：km = KMeans(n_clusters=4)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Expenses:4441.04</span><br><span class="line">[&apos;安徽&apos;, &apos;湖南&apos;, &apos;湖北&apos;, &apos;广西&apos;, &apos;海南&apos;, &apos;四川&apos;, &apos;云南&apos;]</span><br><span class="line">Expenses:7754.66</span><br><span class="line">[&apos;北京&apos;, &apos;上海&apos;, &apos;广东&apos;]</span><br><span class="line">Expenses:3788.76</span><br><span class="line">[&apos;河北&apos;, &apos;山西&apos;, &apos;内蒙古&apos;, &apos;辽宁&apos;, &apos;吉林&apos;, &apos;黑龙江&apos;, &apos;江西&apos;, &apos;山东&apos;, &apos;河南&apos;, &apos;贵州&apos;, &apos;陕西&apos;, &apos;甘肃&apos;, &apos;青海&apos;, &apos;宁夏&apos;, &apos;新疆&apos;]</span><br><span class="line">Expenses:5567.33</span><br><span class="line">[&apos;天津&apos;, &apos;江苏&apos;, &apos;浙江&apos;, &apos;福建&apos;, &apos;重庆&apos;, &apos;西藏&apos;]</span><br></pre></td></tr></table></figure>

<p>从结果可以看出消费水平相近的省市聚集在了一类，例如消费最高的“北京”“上海”“广东”聚集在了消费最高的类别。聚4类时，结果可以比较明显的看出消费层级。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-无监督学习.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-无监督学习.html" itemprop="url">Python机器学习应用 | 无监督学习</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-27T14:13:16+08:00">
                2017-06-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-无监督学习"><a href="#1-无监督学习" class="headerlink" title="1 无监督学习"></a>1 无监督学习</h2><p>利用无标签的数据学习数据的分布或数据与数据之间的关系被称作无监督学习。<br>有监督学习和无监督学习的最大区别在于数据是否有标签<br>无监督学习最常应用的场景是聚类(clustering)和降维(DimensionReduction)</p>
<h2 id="2-聚类-clustering"><a href="#2-聚类-clustering" class="headerlink" title="2 聚类(clustering)"></a>2 聚类(clustering)</h2><p>聚类(clustering)，就是根据数据的“相似性”将数据分为多类的过程。<br>评估两个不同样本之间的“相似性” ，通常使用的方法就是计算两个样本之间的“距离”。使用不同的方法计算样本间的距离会关系到聚类结果的好坏。<br><img src="http://oltfslql1.bkt.clouddn.com/cluster.jpg" alt></p>
<h2 id="3-距离计算"><a href="#3-距离计算" class="headerlink" title="3 距离计算"></a>3 距离计算</h2><h3 id="3-1-欧氏距离"><a href="#3-1-欧氏距离" class="headerlink" title="3.1 欧氏距离"></a>3.1 欧氏距离</h3><p>欧氏距离是最常用的一种距离度量方法，源于欧式空间中两点的距离。其计算方法如下：<br>$$d = \sqrt{\sum_{n=1}^{k} (x_{1k}-x_{2k})^2}$$</p>
<h3 id="3-2-曼哈顿距离"><a href="#3-2-曼哈顿距离" class="headerlink" title="3.2 曼哈顿距离"></a>3.2 曼哈顿距离</h3><p>曼哈顿距离也称作“城市街区距离”，类似于在城市之中驾车行驶，从一个十字路口到另外一个十字楼口的距离。其计算方法如下：<br>$$d = \sum_{n=1}^{k} |x_{1k}-x_{2k}|$$</p>
<h3 id="3-3-马氏距离"><a href="#3-3-马氏距离" class="headerlink" title="3.3 马氏距离"></a>3.3 马氏距离</h3><p>马氏距离表示数据的协方差距离，是一种尺度无关的度量方式。也就是说马氏距离会先将样本点的各个属性标准化，再计算样本间的距离。其计算方式如下：（s是协方差矩阵，如图）<br><img src="http://oltfslql1.bkt.clouddn.com/dist.jpg" alt><br>$$d(x_i,y_j)=\sqrt{(x_i-y_j)^Ts^{-1}(x_i-y_j)}$$</p>
<h3 id="3-4-夹角余弦"><a href="#3-4-夹角余弦" class="headerlink" title="3.4 夹角余弦"></a>3.4 夹角余弦</h3><p>余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个样本差异的大小。余弦值越接近1，说明两个向量夹角越接近0度，表明两个向量越相似。其计算方法如下：<br>$$cos(\theta)=\frac{\sum_{k=1}^{n} x_{1k} x_{2k}}{\sqrt{\sum_{k=1}^{n}x_{1k}^2} \sqrt{\sum_{k=1}^{n}x_{2k}^2}}$$</p>
<h2 id="4-Sklearn-vs-聚类"><a href="#4-Sklearn-vs-聚类" class="headerlink" title="4 Sklearn vs. 聚类"></a>4 Sklearn vs. 聚类</h2><p>scikit-learn库（以后简称sklearn库）提供的常用聚类算法函数包含在sklearn.cluster这个模块中，如：K-Means，近邻传播算法，DBSCAN，等。<br>以同样的数据集应用于不同的算法，可能会得到不同的结果，算法所耗费的时间也不尽相同，这是由算法的特性决定的。<br><img src="http://oltfslql1.bkt.clouddn.com/pic1.jpg" alt><img src="http://oltfslql1.bkt.clouddn.com/pic2.jpg" alt></p>
<h2 id="5-sklearn-cluster"><a href="#5-sklearn-cluster" class="headerlink" title="5 sklearn.cluster"></a>5 sklearn.cluster</h2><p>sklearn.cluster模块提供的各聚类算法函数可以使用不同的数据形式作为输入:<br>标准数据输入格式:[样本个数，特征个数]定义的矩阵形式。<br>相似性矩阵输入格式：即由[样本数目，样本数目]定义的矩阵形式，矩阵中的每一个元素为两个样本的相似度，如DBSCAN， AffinityPropagation(近邻传播算法)接受这种输入。如果以余弦相似度为例，则对角线元素全为1. 矩阵中每个元素的取值范围为[0,1]。<br><img src="http://oltfslql1.bkt.clouddn.com/tabletable.jpg" alt></p>
<h2 id="6-降维"><a href="#6-降维" class="headerlink" title="6 降维"></a>6 降维</h2><p>降维，就是在保证数据所具有的代表性特性或者分布的情况下，将高维数据转化为低维数据的过程：</p>
<ul>
<li>数据的可视化</li>
<li>精简数据<br><img src="http://oltfslql1.bkt.clouddn.com/cl.jpg" alt></li>
</ul>
<h2 id="7-sklearn-vs-降维"><a href="#7-sklearn-vs-降维" class="headerlink" title="7 sklearn vs.降维"></a>7 sklearn vs.降维</h2><ul>
<li>降维是机器学习领域的一个重要研究内容，有很多被工业界和学术界接受的典型算法，截止到目前sklearn库提供7种降维算法。</li>
<li>降维过程也可以被理解为对数据集的组成成份进行分解（decomposition）的过程，因此sklearn为降维模块命名为decomposition, 在对降维算法调用需要使用sklearn.decomposition模块</li>
</ul>
<h2 id="8-sklearn-decomposition"><a href="#8-sklearn-decomposition" class="headerlink" title="8 sklearn.decomposition"></a>8 sklearn.decomposition</h2><p><img src="http://oltfslql1.bkt.clouddn.com/tabeltable2.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-KNN实现手写识别.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-KNN实现手写识别.html" itemprop="url">Python机器学习应用 | KNN实现手写识别</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-26T18:08:33+08:00">
                2017-06-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-任务介绍"><a href="#1-任务介绍" class="headerlink" title="1 任务介绍"></a>1 任务介绍</h2><p>手写数字识别是一个多分类问题，共有10个分类，每个手写数字图像的类别标签是0~9中的其中一个数。例如下面这三张图片的标签分别是0，1，2。<br><img src="http://oltfslql1.bkt.clouddn.com/012.jpg" alt><br>本实例利用sklearn来训练一个K最近邻（k-Nearest Neighbor，KNN）分类器，用于识别数据集DBRHD的手写数字。<br>比较KNN的识别效果与多层感知机的识别效果。</p>
<h2 id="2-KNN的输入"><a href="#2-KNN的输入" class="headerlink" title="2 KNN的输入"></a>2 KNN的输入</h2><p>DBRHD数据集的每个图片是一个由0或1组成的32<em>32的文本矩阵；<br>KNN的输入为图片矩阵展开的1</em>1024个神经元。</p>
<h2 id="3-KNN手写识别实体构建"><a href="#3-KNN手写识别实体构建" class="headerlink" title="3 KNN手写识别实体构建"></a>3 KNN手写识别实体构建</h2><p>本实例的构建步骤如下：<br>步骤1：建立工程并导入sklearn包<br>步骤2：加载训练数据<br>步骤3：构建KNN分类器<br>步骤4：测试集评价</p>
<h3 id="3-1-步骤1：建立工程并导入sklearn包"><a href="#3-1-步骤1：建立工程并导入sklearn包" class="headerlink" title="3.1 步骤1：建立工程并导入sklearn包"></a>3.1 步骤1：建立工程并导入sklearn包</h3><p>1）创建sklearnKNN.py文件<br>2）在sklearnKNN.py文件中导入sklearn相关包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np     #导入numpy工具包</span><br><span class="line">from os import listdir #使用listdir模块，用于访问本地文件</span><br><span class="line">from sklearn import neighbors</span><br></pre></td></tr></table></figure>

<h3 id="3-2-步骤2：加载训练数据"><a href="#3-2-步骤2：加载训练数据" class="headerlink" title="3.2 步骤2：加载训练数据"></a>3.2 步骤2：加载训练数据</h3><p>1）在sklearnKNN.py文件中，定义img2vector函数，将加载的32*32的图片矩阵展开成一列向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def img2vector(fileName):    </span><br><span class="line">    retMat = np.zeros([1024],int) #定义返回的矩阵，大小为1*1024</span><br><span class="line">    fr = open(fileName)           #打开包含32*32大小的数字文件 </span><br><span class="line">    lines = fr.readlines()        #读取文件的所有行</span><br><span class="line">    for i in range(32):           #遍历文件所有行</span><br><span class="line">        for j in range(32):       #并将01数字存放在retMat中     </span><br><span class="line">            retMat[i*32+j] = lines[i][j]    </span><br><span class="line">    return retMat</span><br></pre></td></tr></table></figure>

<p>2）在sklearnKNN.py文件中定义加载训练数据的函数readDataSet。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def readDataSet(path):    </span><br><span class="line">    fileList = listdir(path)    #获取文件夹下的所有文件 </span><br><span class="line">    numFiles = len(fileList)    #统计需要读取的文件的数目</span><br><span class="line">    dataSet = np.zeros([numFiles,1024],int)    #用于存放所有的数字文件</span><br><span class="line">    hwLabels = np.zeros([numFiles])#用于存放对应的标签(与神经网络的不同)</span><br><span class="line">    for i in range(numFiles):      #遍历所有的文件</span><br><span class="line">        filePath = fileList[i]     #获取文件名称/路径   </span><br><span class="line">        digit = int(filePath.split(&apos;_&apos;)[0])   #通过文件名获取标签     </span><br><span class="line">        hwLabels[i] = digit        #直接存放数字，并非one-hot向量</span><br><span class="line">        dataSet[i] = img2vector(path +&apos;/&apos;+filePath)    #读取文件内容 </span><br><span class="line">    return dataSet,hwLabels</span><br></pre></td></tr></table></figure>

<p>3）在sklearnKNN.py文件中，调用readDataSet和img2vector函数加载数据，将训练的图片存放在train_dataSet中，对应的标签则存在train_hwLabels中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataSet, train_hwLabels = readDataSet(&apos;trainingDigits&apos;)</span><br></pre></td></tr></table></figure>

<h3 id="3-3-步骤3：构建KNN分类器"><a href="#3-3-步骤3：构建KNN分类器" class="headerlink" title="3.3 步骤3：构建KNN分类器"></a>3.3 步骤3：构建KNN分类器</h3><p>在sklearnKNN.py文件中，构建KNN分类器：设置查找算法以及邻居点数量(k)值。<br>KNN是一种懒惰学习法，没有学习过程，只在预测时去查找最近邻的点，<br>数据集的输入就是构建KNN分类器的过程。<br>构建KNN时我们同时调用了fit函数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">knn = neighbors.KNeighborsClassifier(algorithm=&apos;kd_tree&apos;, n_neighbors=3)</span><br><span class="line">knn.fit(train_dataSet, train_hwLabels)</span><br></pre></td></tr></table></figure>

<h3 id="3-4-步骤4：测试集评价"><a href="#3-4-步骤4：测试集评价" class="headerlink" title="3.4 步骤4：测试集评价"></a>3.4 步骤4：测试集评价</h3><p>1）加载测试集：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#read  testing dataSet</span><br><span class="line">dataSet,hwLabels = readDataSet(&apos;testDigits&apos;)</span><br></pre></td></tr></table></figure>

<p>2）使用构建好的KNN分类器对测试集进行预测，并计算预测的错误率</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">res = knn.predict(dataSet)  #对测试集进行预测</span><br><span class="line">error_num = np.sum(res != hwLabels) #统计分类错误的数目</span><br><span class="line">num = len(dataSet)          #测试集的数目</span><br><span class="line">print(&quot;Total num:&quot;,num,&quot; Wrong num:&quot;, \</span><br><span class="line">      error_num,&quot;  WrongRate:&quot;,error_num / float(num))</span><br></pre></td></tr></table></figure>

<h2 id="4-实验效果"><a href="#4-实验效果" class="headerlink" title="4 实验效果"></a>4 实验效果</h2><p>邻居数量K影响分析：设置K为1、3、5、7的KNN分类器，对比他们的实验效果<br>| n_neighbors | 1 | 3 | 5 | 7 |<br>| :–: | :–: | :–: | :–: | :–: | :–: |<br>| error_num |  13 |  12 |  18 | 22  |<br>| RightRate |  0.9863 | 0.9873  |  0.9810 |  0.9767 | </p>
<p>K=3时正确率最高，当K&gt;3时正确率开始下降，这是由于当样本为稀疏数据集时（本实例只有946个样本），其第k个邻居点可能与测试点距离较远，因此投出了错误的一票进而影响了最终预测结果。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-MLP实现手写识别.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-MLP实现手写识别.html" itemprop="url">Python机器学习应用 | MLP实现手写识别</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-25T21:42:45+08:00">
                2017-06-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-任务介绍"><a href="#1-任务介绍" class="headerlink" title="1 任务介绍"></a>1 任务介绍</h2><p>手写数字识别是一个多分类问题，共有10个分类，每个手写数字图像的类别标签是0~9中的其中一个数。例如下面这三张图片的标签分别是0，1，2。<br><img src="http://oltfslql1.bkt.clouddn.com/012.jpg" alt><br>任务：利用sklearn来训练一个简单的全连接神经网络，即多层感知机（Multilayer perceptron，MLP）用于识别数据集DBRHD的手写数字。</p>
<h2 id="2-MLP的输入"><a href="#2-MLP的输入" class="headerlink" title="2 MLP的输入"></a>2 MLP的输入</h2><p>DBRHD数据集的每个图片是一个由0或1组成的32<em>32的文本矩阵；<br>多层感知机的输入为图片矩阵展开的1</em>1024个神经元。</p>
<h2 id="3-MLP的输出"><a href="#3-MLP的输出" class="headerlink" title="3 MLP的输出"></a>3 MLP的输出</h2><p>MLP输出：“one-hot vectors”<br>一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。<br>图片标签将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成[1,0,0,0,0,0,0,0,0,0,0]。即，MLP输出层具有10个神经元。</p>
<h2 id="4-MLP结构"><a href="#4-MLP结构" class="headerlink" title="4 MLP结构"></a>4 MLP结构</h2><p>MLP的输入与输出层，中间隐藏层的层数和神经元的个数设置都将影响该MLP模型的准确率。<br>在本实例中，我们只设置一层隐藏层，在后续实验中比较该隐藏层神经元个数为50、100、200时的MLP效果。<br><img src="http://oltfslql1.bkt.clouddn.com/mlp.jpg" alt></p>
<h2 id="5-MLP手写识别实例构建"><a href="#5-MLP手写识别实例构建" class="headerlink" title="5 MLP手写识别实例构建"></a>5 MLP手写识别实例构建</h2><p>本实例的构建步骤如下：<br>步骤1：建立工程并导入sklearn包<br>步骤2：加载训练数据<br>步骤3：训练神经网络<br>步骤4：测试集评价</p>
<h3 id="5-1-步骤1：建立工程并导入sklearn包"><a href="#5-1-步骤1：建立工程并导入sklearn包" class="headerlink" title="5.1 步骤1：建立工程并导入sklearn包"></a>5.1 步骤1：建立工程并导入sklearn包</h3><p>1)创建sklearnBP.py文件<br>2)在sklearnBP.py文件中导入sklearn相关包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np #导入numpy工具包</span><br><span class="line">from os import listdir #使用listdir模块，用于访问本地文件</span><br><span class="line">from sklearn.neural_network import MLPClassifier</span><br></pre></td></tr></table></figure>

<h3 id="5-2-步骤2：加载训练数据"><a href="#5-2-步骤2：加载训练数据" class="headerlink" title="5.2 步骤2：加载训练数据"></a>5.2 步骤2：加载训练数据</h3><p>1）在sklearnBP.py文件中，定义img2vector函数，将加载的32*32的图片矩阵展开成一列向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def img2vector(fileName):</span><br><span class="line">	retMat = np.zeros([1024],int) #定义返回的矩阵，大小为1*1024</span><br><span class="line">	fr = open(fileName) #打开包含32*32大小的数字文件</span><br><span class="line">	lines = fr.readlines() #读取文件的所有行</span><br><span class="line">	for i in range(32): #遍历文件所有行</span><br><span class="line">		for j in range(32): #并将01数字存放在retMat中</span><br><span class="line">			retMat[i*32+j] = lines[i][j]</span><br><span class="line">	return retMat</span><br></pre></td></tr></table></figure>

<p>2）在sklearnBP.py文件中定义加载训练数据的函数readDataSet，并将样本标签转化为one-hot向量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def readDataSet(path):    </span><br><span class="line">    fileList = listdir(path)    #获取文件夹下的所有文件 </span><br><span class="line">    numFiles = len(fileList)    #统计需要读取的文件的数目</span><br><span class="line">    dataSet = np.zeros([numFiles,1024],int) #用于存放所有的数字文件</span><br><span class="line">    hwLabels = np.zeros([numFiles,10])      #用于存放对应的one-hot标签</span><br><span class="line">    for i in range(numFiles):   #遍历所有的文件</span><br><span class="line">        filePath = fileList[i]  #获取文件名称/路径      </span><br><span class="line">        digit = int(filePath.split(&apos;_&apos;)[0])  #通过文件名获取标签      </span><br><span class="line">        hwLabels[i][digit] = 1.0        #将对应的one-hot标签置1</span><br><span class="line">        dataSet[i] = img2vector(path +&apos;/&apos;+filePath) #读取文件内容   </span><br><span class="line">    return dataSet,hwLabels</span><br></pre></td></tr></table></figure>

<p>3）在sklearnBP.py文件中，调用readDataSet和img2vector函数加载数据，将训练的图片存放在train_dataSet中，对应的标签则存在train_hwLabels中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#read dataSet</span><br><span class="line">train_dataSet, train_hwLabels = readDataSet(&apos;trainingDigits&apos;)</span><br></pre></td></tr></table></figure>

<h3 id="5-3-步骤3：训练神经网络"><a href="#5-3-步骤3：训练神经网络" class="headerlink" title="5.3 步骤3：训练神经网络"></a>5.3 步骤3：训练神经网络</h3><p>1）在sklearnBP.py文件中，构建神经网络：设置网络的隐藏层数、各隐藏层神经元个数、激活函数、学习率、优化方法、最大迭代次数。<br>设置含100个神经元的隐藏层。<br>hidden_layer_sizes存放的是一个元组，表示第i层隐藏层里神经元的个数<br>使用logistic激活函数和adam优化方法，并令初始学习率为0.0001</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clf = MLPClassifier(hidden_layer_sizes=(100,),</span><br><span class="line">                    activation=&apos;logistic&apos;, solver=&apos;adam&apos;,</span><br><span class="line">                    learning_rate_init = 0.0001, max_iter=2000)</span><br></pre></td></tr></table></figure>

<p>2）在sklearnBP.py文件中，使用训练数据训练构建好的神经网络fit函数能够根据训练集及对应标签集自动设置多层感知机的输入与输<br>出层的神经元个数。<br>例如train_dataSet为n<em>1024的矩阵，train_hwLabels为n</em>10的矩阵，则fit函数将MLP的输入层神经元个数设为1024，输出层神经元个数为10：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf.fit(train_dataSet,train_hwLabels)</span><br></pre></td></tr></table></figure>

<h3 id="5-4-步骤4：测试集评价"><a href="#5-4-步骤4：测试集评价" class="headerlink" title="5.4 步骤4：测试集评价"></a>5.4 步骤4：测试集评价</h3><p>1）在sklearnBP.py文件中，加载测试集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataSet,hwLabels = readDataSet(&apos;testDigits&apos;)</span><br></pre></td></tr></table></figure>

<p>2）使用训练好的MLP对测试集进行预测，并计算错误率：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">res = clf.predict(dataSet)   #对测试集进行预测</span><br><span class="line">error_num = 0                #统计预测错误的数目</span><br><span class="line">num = len(dataSet)           #测试集的数目</span><br><span class="line">for i in range(num):         #遍历预测结果</span><br><span class="line">    #比较长度为10的数组，返回包含01的数组，0为不同，1为相同</span><br><span class="line">    #若预测结果与真实结果相同，则10个数字全为1，否则不全为1</span><br><span class="line">    if np.sum(res[i] == hwLabels[i]) &lt; 10: </span><br><span class="line">        error_num += 1                     </span><br><span class="line">print(&quot;Total num:&quot;,num,&quot; Wrong num:&quot;, \</span><br><span class="line">      error_num,&quot;  WrongRate:&quot;,error_num / float(num))</span><br></pre></td></tr></table></figure>

<h2 id="6-实验效果"><a href="#6-实验效果" class="headerlink" title="6 实验效果"></a>6 实验效果</h2><h3 id="6-1-隐藏层神经元个数影响"><a href="#6-1-隐藏层神经元个数影响" class="headerlink" title="6.1 隐藏层神经元个数影响"></a>6.1 隐藏层神经元个数影响</h3><p>运行隐藏层神经元个数为50、100、200的多层感知机，对比实验效果：<br><img src="http://oltfslql1.bkt.clouddn.com/table22.jpg" alt><br>随着隐藏层神经元个数的增加，MLP的正确率持上升趋势；<br>大量的隐藏层神经元带来的计算负担与对结果的提升并不对等，因此，如何选取合适的隐藏神经元个数是一个值得探讨的问题。</p>
<h3 id="6-2-迭代次数影响分析"><a href="#6-2-迭代次数影响分析" class="headerlink" title="6.2 迭代次数影响分析"></a>6.2 迭代次数影响分析</h3><p>我们设隐藏层神经元个数为100，初始学习率为0.0001，最大迭代次数分别为500、1000、1500、2000, 结果如下：<br><img src="http://oltfslql1.bkt.clouddn.com/table23.jpg" alt><br>过小的迭代次数可能使得MLP早停，造成较低的正确率。<br>当最大迭代次数&gt;1000时，正确率基本保持不变，这说明MLP在第1000迭代时已收敛，剩余的迭代次数不再进行。</p>
<h3 id="6-3-学习率影响分析"><a href="#6-3-学习率影响分析" class="headerlink" title="6.3 学习率影响分析"></a>6.3 学习率影响分析</h3><p>改用随机梯度下降优化算法即将MLPclassifer的参数（ solver=‘sgd’, ），设隐藏层神经元个数为100，最大迭代次数为2000，学习率分别为：0.1、0.01、0.001、0.0001，结果如下：<br><img src="http://oltfslql1.bkt.clouddn.com/table24.jpg" alt><br>结论：较小的学习率带来了更低的正确率，这是因为较小学习率无法在2000次迭代内完成收敛，而步长较大的学习率使得MLP在2000次迭代内快速收敛到最优解。因此，较小的学习率一般要配备较大的迭代次数以保证其收敛。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-多项式回归.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-多项式回归.html" itemprop="url">Python机器学习应用 | 多项式回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-24T14:16:49+08:00">
                2017-06-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-多项式回归"><a href="#1-多项式回归" class="headerlink" title="1 多项式回归"></a>1 多项式回归</h2><p>多项式回归(Polynomial Regression)是研究一个因变量与一个或多个自变量间多项式的回归分析方法。如果自变量只有一个时，称为一元多项式回归；如果自变量有多个时，称为多元多项式回归。<br>在一元回归分析中，如果依变量y与自变量x的关系为非线性的，但是又找不到适当的函数曲线来拟合，则可以采用一元多项式回归。<br>多项式回归的最大优点就是可以通过增加x的高次项对实测点进行逼近，直至满意为止。<br>事实上，多项式回归可以处理相当一类非线性问题，它在回归分析中占有重要的地位，因为任一函数都可以分段用多项式来逼近。<br><img src="http://oltfslql1.bkt.clouddn.com/2pic.jpg" alt><br>之前提到的线性回归实例中，是运用直线来拟合数据输入与输出之间的线性关系。不同于线性回归，多项式回归是使用曲线拟合数据的输入与输出的映射关系。</p>
<h2 id="2-多项式回归的应用"><a href="#2-多项式回归的应用" class="headerlink" title="2 多项式回归的应用"></a>2 多项式回归的应用</h2><h3 id="2-1-应用背景"><a href="#2-1-应用背景" class="headerlink" title="2.1 应用背景"></a>2.1 应用背景</h3><p>我们在前面已经根据已知的房屋成交价和房屋的尺寸进行了线性回归，继而可以对已知房屋尺寸，而未知房屋成交价格的实例进行了成交价格的预测，但是在实际的应用中这样的拟合往往不够好，因此我们在此对该数据集进行多项式回归。</p>
<p>目标：对房屋成交信息建立多项式回归方程，并依据回归方程对房屋价格进行预测<br>技术路线：sklearn.preprocessing.PolynomialFeatures</p>
<h3 id="2-2-实例数据"><a href="#2-2-实例数据" class="headerlink" title="2.2 实例数据"></a>2.2 实例数据</h3><p>为了方便展示，成交信息只使用了房屋的面积以及对应的成交价格。其中：<br>• 房屋面积单位为平方英尺（ft2）房<br>• 屋成交价格单位为万<br><img src="http://oltfslql1.bkt.clouddn.com/table.jpg" alt></p>
<h3 id="2-3-实验过程"><a href="#2-3-实验过程" class="headerlink" title="2.3 实验过程"></a>2.3 实验过程</h3><p>使用算法：线性回归<br>实现步骤：<br>1.建立工程并导入sklearn包<br>2.加载训练数据，建立回归方程<br>3.可视化处理</p>
<h3 id="2-4-实现步骤"><a href="#2-4-实现步骤" class="headerlink" title="2.4 实现步骤"></a>2.4 实现步骤</h3><h4 id="2-4-1-建立工程并导入sklearn包"><a href="#2-4-1-建立工程并导入sklearn包" class="headerlink" title="2.4.1 建立工程并导入sklearn包"></a>2.4.1 建立工程并导入sklearn包</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import linear_model</span><br><span class="line">from sklearn.preprocessing import PolynomialFeatures</span><br></pre></td></tr></table></figure>

<h4 id="2-4-2-加载训练数据，建立回归方程"><a href="#2-4-2-加载训练数据，建立回归方程" class="headerlink" title="2.4.2 加载训练数据，建立回归方程"></a>2.4.2 加载训练数据，建立回归方程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># 读取数据集</span><br><span class="line">datasets_X = []</span><br><span class="line">datasets_Y = []</span><br><span class="line">fr = open(&apos;prices.txt&apos;,&apos;r&apos;)</span><br><span class="line">lines = fr.readlines()</span><br><span class="line">for line in lines:</span><br><span class="line">    items = line.strip().split(&apos;,&apos;)</span><br><span class="line">    datasets_X.append(int(items[0]))</span><br><span class="line">    datasets_Y.append(int(items[1]))</span><br><span class="line"> </span><br><span class="line">length = len(datasets_X)</span><br><span class="line">datasets_X = np.array(datasets_X).reshape([length,1])</span><br><span class="line">datasets_Y = np.array(datasets_Y)</span><br><span class="line"> </span><br><span class="line">minX = min(datasets_X)</span><br><span class="line">maxX = max(datasets_X)</span><br><span class="line">X = np.arange(minX,maxX).reshape([-1,1])</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">poly_reg = PolynomialFeatures(degree = 2)</span><br><span class="line">X_poly = poly_reg.fit_transform(datasets_X)</span><br><span class="line">lin_reg_2 = linear_model.LinearRegression()</span><br><span class="line">lin_reg_2.fit(X_poly, datasets_Y)</span><br></pre></td></tr></table></figure>

<h4 id="2-4-3-可视化处理"><a href="#2-4-3-可视化处理" class="headerlink" title="2.4.3 可视化处理"></a>2.4.3 可视化处理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 图像中显示</span><br><span class="line">plt.scatter(datasets_X, datasets_Y, color = &apos;red&apos;)</span><br><span class="line">plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)), color = &apos;blue&apos;)</span><br><span class="line">plt.xlabel(&apos;Area&apos;)</span><br><span class="line">plt.ylabel(&apos;Price&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="2-5-结果展示"><a href="#2-5-结果展示" class="headerlink" title="2.5 结果展示"></a>2.5 结果展示</h3><p>通过多项式回归拟合的曲线与数据点的关系如右图所示。依据该多项式回归方程即可通过房屋的尺寸，来预测房屋的成交价格。<br><img src="http://7xpp0b.com1.z0.glb.clouddn.com/prices22.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="www.dongjinbao.com/机器学习/Python机器学习应用-线性回归.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JinbaoSite">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="JinbaoSite">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/机器学习/Python机器学习应用-线性回归.html" itemprop="url">Python机器学习应用 | 线性回归</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-24T11:00:48+08:00">
                2017-06-24
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="1-线性回归"><a href="#1-线性回归" class="headerlink" title="1 线性回归"></a>1 线性回归</h2><p>线性回归(Linear Regression)是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。<br>线性回归利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。</p>
<p>线性回归：使用形如$y=w^Tx+b$的线性模型拟合数据输入和输出之间的映射关系的。<br><img src="http://oltfslql1.bkt.clouddn.com/l.jpg" alt></p>
<h2 id="2-线性回归的实际用途"><a href="#2-线性回归的实际用途" class="headerlink" title="2 线性回归的实际用途"></a>2 线性回归的实际用途</h2><p>线性回归有很多实际的用途，分为以下两类：<br>1.如果目标是预测或者映射，线性回归可以用来对观测数据集的y和X的值拟合出一个预测模型。当完成这样一个模型以后，对于一个新增的X值，在没有给定与它相配对的y的情况下，可以用这个拟合过的模型预测出一个y值。<br>2.给定一个变量y和一些变量$X_1,…,X_p$,这些变量有可能与y相关，线性回归分析可以用来量化y与$X_j$之间相关性的强度，评估出与y不相关的$X_j$，并识别出哪些$X_j$的子集包含了关于y的冗余信息。</p>
<h2 id="3-线性回归的应用"><a href="#3-线性回归的应用" class="headerlink" title="3 线性回归的应用"></a>3 线性回归的应用</h2><h3 id="3-1-背景"><a href="#3-1-背景" class="headerlink" title="3.1 背景"></a>3.1 背景</h3><p>与房价密切相关的除了单位的房价，还有房屋的尺寸。我们可以根据已知的房屋成交价和房屋的尺寸进行线性回归，继而可以对已知房屋尺寸，而未知房屋成交价格的实例进行成交价格的预测。</p>
<p>目标：对房屋成交信息建立回归方程，并依据回归方程对房屋价格进行预测<br>技术路线：sklearn.linear_model.LinearRegression</p>
<h3 id="3-2-实例数据"><a href="#3-2-实例数据" class="headerlink" title="3.2 实例数据"></a>3.2 实例数据</h3><p>为了方便展示，成交信息只使用了房屋的面积以及对应的成交价格。其中：<br>• 房屋面积单位为平方英尺（ft2）房<br>• 屋成交价格单位为万<br><img src="http://oltfslql1.bkt.clouddn.com/table.jpg" alt></p>
<h3 id="3-3-可行性分析"><a href="#3-3-可行性分析" class="headerlink" title="3.3 可行性分析"></a>3.3 可行性分析</h3><p>简单而直观的方式是通过数据的可视化直接观察房屋成交价格与房屋尺寸间是否存在线性关系。<br>对于本实验的数据来说，散点图就可以很好的将其在二维平面中进行可视化表示。</p>
<p>下图为数据的散点图，其中横坐标为房屋面积，纵坐标为房屋的成交价格。可以看出，靠近坐标左下角部分的点，表示房屋尺寸较小的房子，其对应的房屋成交价格也相对较低。同样的，靠近坐标右上部分的点对应于大尺寸高价格的房屋。从总体来看，房屋的面积和成交价格基本成正比。<br><img src="http://oltfslql1.bkt.clouddn.com/2table.jpg" alt></p>
<h3 id="3-4-实验过程"><a href="#3-4-实验过程" class="headerlink" title="3.4 实验过程"></a>3.4 实验过程</h3><p>使用算法：线性回归<br>实现步骤：<br>1.建立工程并导入sklearn包<br>2.加载训练数据，建立回归方程<br>3.可视化处理</p>
<h3 id="3-5-实现步骤"><a href="#3-5-实现步骤" class="headerlink" title="3.5 实现步骤"></a>3.5 实现步骤</h3><h4 id="3-5-1-建立工程并导入sklearn包"><a href="#3-5-1-建立工程并导入sklearn包" class="headerlink" title="3.5.1 建立工程并导入sklearn包"></a>3.5.1 建立工程并导入sklearn包</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from sklearn import linear_model</span><br></pre></td></tr></table></figure>

<h4 id="3-5-2-加载训练数据，建立回归方程"><a href="#3-5-2-加载训练数据，建立回归方程" class="headerlink" title="3.5.2 加载训练数据，建立回归方程"></a>3.5.2 加载训练数据，建立回归方程</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 读取数据集</span><br><span class="line">datasets_X = []</span><br><span class="line">datasets_Y = []</span><br><span class="line">fr = open(&apos;prices.txt&apos;,&apos;r&apos;)</span><br><span class="line">lines = fr.readlines()</span><br><span class="line">for line in lines:</span><br><span class="line">    items = line.strip().split(&apos;,&apos;)</span><br><span class="line">    datasets_X.append(int(items[0]))</span><br><span class="line">    datasets_Y.append(int(items[1]))</span><br><span class="line"> </span><br><span class="line">length = len(datasets_X)</span><br><span class="line">datasets_X = np.array(datasets_X).reshape([length,1])</span><br><span class="line">datasets_Y = np.array(datasets_Y)</span><br><span class="line"></span><br><span class="line">minX = min(datasets_X)</span><br><span class="line">maxX = max(datasets_X)</span><br><span class="line">X = np.arange(minX,maxX).reshape([-1,1])</span><br><span class="line"></span><br><span class="line">linear = linear_model.LinearRegression()</span><br><span class="line">linear.fit(datasets_X, datasets_Y)</span><br></pre></td></tr></table></figure>

<h4 id="3-5-3-可视化处理"><a href="#3-5-3-可视化处理" class="headerlink" title="3.5.3 可视化处理"></a>3.5.3 可视化处理</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 图像中显示</span><br><span class="line">plt.scatter(datasets_X, datasets_Y, color = &apos;red&apos;)</span><br><span class="line">plt.plot(X, linear.predict(X), color = &apos;blue&apos;)</span><br><span class="line">plt.xlabel(&apos;Area&apos;)</span><br><span class="line">plt.ylabel(&apos;Price&apos;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h3 id="3-6-结果展示"><a href="#3-6-结果展示" class="headerlink" title="3.6 结果展示"></a>3.6 结果展示</h3><p>通过回归方程拟合的直线与原有数据点的关系如右图所示，依据该回归方程即可通过房屋的尺寸，来预测房屋的成交价格。<br><img src="http://oltfslql1.bkt.clouddn.com/prices.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">JinbaoSite</p>
              <p class="site-description motion-element" itemprop="description">趣头条广告算法工程师</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">58</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JinbaoSite</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
